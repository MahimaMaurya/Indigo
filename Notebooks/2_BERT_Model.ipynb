{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahimaMaurya/Indigo/blob/main/Notebooks/2_BERT_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EMC3QNL_v9Rh",
        "outputId": "9fdaa2ea-47bf-4e6f-9fa1-7ae2404c044a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Pa3uks_6oyUp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForQuestionAnswering\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import logging\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "id": "aj7c4rC0_bNn",
        "outputId": "020f47b0-2538-49f4-a74c-3c1ea23737ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0  How can a piece of paper folded 103 times be l...   \n",
              "1  Did a landlord ever offer to lower your rent s...   \n",
              "2  If the Von Karman line is 62 miles above, then...   \n",
              "3  Do soldiers pick up fallen enemy weapons to us...   \n",
              "4          How do I get my son to stop making music?   \n",
              "\n",
              "                                  tokenized_question  \\\n",
              "0  ['how', 'can', 'a', 'piece', 'of', 'paper', 'f...   \n",
              "1  ['did', 'a', 'landlord', 'ever', 'offer', 'to'...   \n",
              "2  ['if', 'the', 'von', 'karman', 'line', 'is', '...   \n",
              "3  ['do', 'soldiers', 'pick', 'up', 'fallen', 'en...   \n",
              "4  ['how', 'do', 'i', 'get', 'my', 'son', 'to', '...   \n",
              "\n",
              "                                    stemmed_question  \\\n",
              "0  ['how', 'can', 'a', 'piec', 'of', 'paper', 'fo...   \n",
              "1  ['did', 'a', 'landlord', 'ever', 'offer', 'to'...   \n",
              "2  ['if', 'the', 'von', 'karman', 'line', 'is', '...   \n",
              "3  ['do', 'soldier', 'pick', 'up', 'fallen', 'ene...   \n",
              "4  ['how', 'do', 'i', 'get', 'my', 'son', 'to', '...   \n",
              "\n",
              "                                              answer  \\\n",
              "0  It isn’t.  It just has a stack height longer t...   \n",
              "1  Did a landlord ever offer to lower your rent s...   \n",
              "2  No. The Karman line has nothing to do with the...   \n",
              "3  It’s against the rules of war so no, if they r...   \n",
              "4  Wha- if he loves making music, let him make mu...   \n",
              "\n",
              "                                    tokenized_answer  \\\n",
              "0  ['it', 'isn’t', 'it', 'just', 'has', 'a', 'sta...   \n",
              "1  ['did', 'a', 'landlord', 'ever', 'offer', 'to'...   \n",
              "2  ['no', 'the', 'karman', 'line', 'has', 'nothin...   \n",
              "3  ['it’s', 'against', 'the', 'rules', 'of', 'war...   \n",
              "4  ['wha', 'if', 'he', 'loves', 'making', 'music'...   \n",
              "\n",
              "                                      stemmed_answer  question_length  \\\n",
              "0  ['it', 'isn’t', 'it', 'just', 'ha', 'a', 'stac...               81   \n",
              "1  ['did', 'a', 'landlord', 'ever', 'offer', 'to'...               72   \n",
              "2  ['no', 'the', 'karman', 'line', 'ha', 'noth', ...              114   \n",
              "3  ['it’', 'against', 'the', 'rule', 'of', 'war',...               89   \n",
              "4  ['wha', 'if', 'he', 'love', 'make', 'music', '...               41   \n",
              "\n",
              "   answer_length  \n",
              "0            119  \n",
              "1            258  \n",
              "2            759  \n",
              "3            379  \n",
              "4            244  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd698f58-9098-4408-b17e-46c80505ec22\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>tokenized_question</th>\n",
              "      <th>stemmed_question</th>\n",
              "      <th>answer</th>\n",
              "      <th>tokenized_answer</th>\n",
              "      <th>stemmed_answer</th>\n",
              "      <th>question_length</th>\n",
              "      <th>answer_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How can a piece of paper folded 103 times be l...</td>\n",
              "      <td>['how', 'can', 'a', 'piece', 'of', 'paper', 'f...</td>\n",
              "      <td>['how', 'can', 'a', 'piec', 'of', 'paper', 'fo...</td>\n",
              "      <td>It isn’t.  It just has a stack height longer t...</td>\n",
              "      <td>['it', 'isn’t', 'it', 'just', 'has', 'a', 'sta...</td>\n",
              "      <td>['it', 'isn’t', 'it', 'just', 'ha', 'a', 'stac...</td>\n",
              "      <td>81</td>\n",
              "      <td>119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Did a landlord ever offer to lower your rent s...</td>\n",
              "      <td>['did', 'a', 'landlord', 'ever', 'offer', 'to'...</td>\n",
              "      <td>['did', 'a', 'landlord', 'ever', 'offer', 'to'...</td>\n",
              "      <td>Did a landlord ever offer to lower your rent s...</td>\n",
              "      <td>['did', 'a', 'landlord', 'ever', 'offer', 'to'...</td>\n",
              "      <td>['did', 'a', 'landlord', 'ever', 'offer', 'to'...</td>\n",
              "      <td>72</td>\n",
              "      <td>258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>If the Von Karman line is 62 miles above, then...</td>\n",
              "      <td>['if', 'the', 'von', 'karman', 'line', 'is', '...</td>\n",
              "      <td>['if', 'the', 'von', 'karman', 'line', 'is', '...</td>\n",
              "      <td>No. The Karman line has nothing to do with the...</td>\n",
              "      <td>['no', 'the', 'karman', 'line', 'has', 'nothin...</td>\n",
              "      <td>['no', 'the', 'karman', 'line', 'ha', 'noth', ...</td>\n",
              "      <td>114</td>\n",
              "      <td>759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Do soldiers pick up fallen enemy weapons to us...</td>\n",
              "      <td>['do', 'soldiers', 'pick', 'up', 'fallen', 'en...</td>\n",
              "      <td>['do', 'soldier', 'pick', 'up', 'fallen', 'ene...</td>\n",
              "      <td>It’s against the rules of war so no, if they r...</td>\n",
              "      <td>['it’s', 'against', 'the', 'rules', 'of', 'war...</td>\n",
              "      <td>['it’', 'against', 'the', 'rule', 'of', 'war',...</td>\n",
              "      <td>89</td>\n",
              "      <td>379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How do I get my son to stop making music?</td>\n",
              "      <td>['how', 'do', 'i', 'get', 'my', 'son', 'to', '...</td>\n",
              "      <td>['how', 'do', 'i', 'get', 'my', 'son', 'to', '...</td>\n",
              "      <td>Wha- if he loves making music, let him make mu...</td>\n",
              "      <td>['wha', 'if', 'he', 'loves', 'making', 'music'...</td>\n",
              "      <td>['wha', 'if', 'he', 'love', 'make', 'music', '...</td>\n",
              "      <td>41</td>\n",
              "      <td>244</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd698f58-9098-4408-b17e-46c80505ec22')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fd698f58-9098-4408-b17e-46c80505ec22 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fd698f58-9098-4408-b17e-46c80505ec22');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-158c84b8-49cd-4431-90dc-d0d1c7555a97\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-158c84b8-49cd-4431-90dc-d0d1c7555a97')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-158c84b8-49cd-4431-90dc-d0d1c7555a97 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 45137,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3164,\n        \"samples\": [\n          \"Why did Anakin not leave Mustafar immediately after he had wiped out the Separatist leaders?\",\n          \"Is it true that Lord Shiva is not mentioned in the Vedas?\",\n          \"What are some NLP techniques every data scientist must know?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokenized_question\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3164,\n        \"samples\": [\n          \"['why', 'did', 'anakin', 'not', 'leave', 'mustafar', 'immediately', 'after', 'he', 'had', 'wiped', 'out', 'the', 'separatist', 'leaders']\",\n          \"['is', 'it', 'true', 'that', 'lord', 'shiva', 'is', 'not', 'mentioned', 'in', 'the', 'vedas']\",\n          \"['what', 'are', 'some', 'nlp', 'techniques', 'every', 'data', 'scientist', 'must', 'know']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stemmed_question\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3164,\n        \"samples\": [\n          \"['whi', 'did', 'anakin', 'not', 'leav', 'mustafar', 'immedi', 'after', 'he', 'had', 'wipe', 'out', 'the', 'separatist', 'leader']\",\n          \"['is', 'it', 'true', 'that', 'lord', 'shiva', 'is', 'not', 'mention', 'in', 'the', 'veda']\",\n          \"['what', 'are', 'some', 'nlp', 'techniqu', 'everi', 'data', 'scientist', 'must', 'know']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 43870,\n        \"samples\": [\n          \"Get personalProvide excellent customer serviceTrain your staffCreate community[LINKED_TEXT: Reward your customers] [URL: https://say2b.com/?utm_source=Quora&utm_medium=Yeva&utm_campaign=Say2B%20Tracking]Encourage customer feedbackShare your valuesBe flexible with policiesBe the best at what you doUse social mediaBe transparentCommunicateGo digitalSpend more time with customersSurprise them Bonus: Video about building customer loyalty in a local business. \",\n          \"Any person who has been in a dust devil (or landspout) could easily defend this line. It is course and rough, and it does get everywhere. We aren\\u2019t talking beach sand here, remember. We\\u2019re talking Tatooine sand.Landspouts whip sand around as though it were snow in a snowstorm. It gets in your eyes as well as everywhere else, and it\\u2019s just plain nasty. \",\n          \"Yeah obviously drax will be in guardians vol.3.  When james gunn get fired there was uncertainty of whether batista will play or not.since he openly said he don\\u2019t think he could play drax under other director but now aince that\\u2019s not the case and james gunn return to direct vol.3, it\\u2019s pretty sure drax will be there and batista will play that role. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokenized_answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 43731,\n        \"samples\": [\n          \"['calais', 'to', 'argeles', 'sur', 'mer', 'about', '700', 'miles', 'about', 'one', 'and', 'a', 'half', 'days', 'with', 'an', 'overnight', 'stop', 'in', 'orleans', 'the', 'viaduc', 'de', 'millau', 'wasn', 't', 'open', 'then', 'though', 'it', 'should', 'be', 'a', 'bit', 'easier', 'now']\",\n          \"['momos', 'pani', 'puri', 'chappal', 'joote', 'from', 'political', 'parties']\",\n          \"['wazwaan', 'is', 'the', 'famous', 'among', 'all', 'foods', 'in', 'kashmir', 'and', 'i', 'think', 'you', 'should', 'try', 'that']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stemmed_answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 43723,\n        \"samples\": [\n          \"['i', 'm', 'not', 'a', 'yank', 'but', 'i', 'll', 'chime', 'in', 'to', 'say', 'this\\u2026', 'the', 'fuckwit', 'that', 'ask', 'thi', 'question', 'is', 'go', 'to', 'be', 'real', 'dismay', 'if', 'they', 'go', 'look', 'up', 'usa', 's', 'global', 'per', 'capita', 'rank', 'in', 'term', 'of', 'crime', 'gun', 'death', 'poverti', 'infant', 'mortal', 'educ', 'intellig', 'and', 'level', 'of', 'ignor']\",\n          \"['quora\\u2019', 'realli', 'reach', 'back', 'to', 'dredg', 'up', 'stuff', 'to', 'put', 'in', 'user', 'feed', 'is', 'all', 'of', 'the', 'current', 'content', 'realli', 'so', 'lowbrow', 'that', 'thi', 'is', 'their', 'onli', 'option', 'anyhow', 'nobodi', 'should', 'be', 'surpris', 'that', 'the', 'answer', 'is', 'ye', 'i\\u2019v', 'caught', 'a', 'bunch', 'of', 'shit', 'for', 'post', 'about', 'have', 'use', 'to', 'work', 'as', 'a', 'stripper', 'i\\u2019v', 'had', 'peopl', 'tri', 'to', 'talk', 'down', 'to', 'me', 'for', 'have', 'a', 'profess', 'which', 'peopl', 'like', 'to', 'consid', '\\u201ca', 'man\\u2019', 'world\\u201d', 'i\\u2019v', 'had', 'dude', 'catfish', 'as', 'lesbian', 'tri', 'to', 'get', 'me', 'to', 'send', 'them', 'pictur', 'i\\u2019v', 'shown', 'up', 'on', 'the', 'radar', 'of', 'incel', 'etc', 'even', 'when', 'quora', 'had', 'the', 'real', 'name', 'polici', 'in', 'effect', 'i\\u2019v', 'never', 'use', 'my', 'real', 'name', 'on', 'thi', 'site', 'and', 'in', 'hindsight', 'i', 'know', 'it', 'wa', 'the', 'right', 'thing', 'to', 'do', 'especi', 'given', 'how', 'quora', 'ha', 'becom', 'pretti', 'much', 'a', 'free', 'for', 'all', 'sinc', 'i', 'first', 'regist', 'on', 'here', 'thi', 'keep', 'the', 'riffraff', 'off', 'of', 'other', 'place', 'where', 'i', 'have', 'a', 'presenc', 'such', 'as', 'social', 'and', 'profession', 'media', 'now', 'that', 'be', 'said', 'you', 'don\\u2019t', 'have', 'to', 'be', 'of', 'the', 'femal', 'persuas', 'to', 'be', 'harass', 'on', 'quora', 'just', 'ask', 'anyon', 'who', 'get', 'involv', 'in', 'polit', 'discuss', 'especi', 'regard', 'us', 'polit']\",\n          \"['when', 'look', 'at', 'find', 'the', 'best', 'car', 'under', '10', 'lakh', 'you', 'would', 'ideal', 'be', 'look', 'at', 'the', 'car', 'that', 'offer', 'the', 'best', 'in', 'term', 'of', 'safeti', 'featur', 'and', 'overal', 'valu', 'with', 'thi', 'in', 'mind', 'here', 'are', 'the', 'most', 'popular', 'car', 'in', 'thi', 'price', 'segment', 'compact', 'suv', 'under', '10', 'lakh', 'tata', 'nexonth', 'tata', 'nexon', 'is', 'the', 'best', 'sell', 'compact', 'suv', 'in', 'india', 'link', 'text', 'owe', 'to', 'it', 'popular', 'url', 'http', 'www', 'spinni', 'com', 'blog', 'index', 'php', 'whi', 'the', 'tata', 'nexon', 'is', 'india', 'most', 'popular', 'compact', 'suv', 'utm', 'medium', 'quora', 'utm', 'sourc', 'whi', 'india', 'love', 'nexon', 'as', 'a', 'safe', 'featur', 'rich', 'car', 'that', 'is', 'also', 'price', 'well', 'premium', 'hatchback', 'under', '10', 'lakh', 'tata', 'altroz', 'maruti', 'balenoth', 'altroz', 'is', 'like', 'the', 'nexon', 'in', 'mani', 'way', 'offer', 'great', 'safeti', 'spaciou', 'interior', 'and', 'a', 'diesel', 'engin', 'option', 'the', 'baleno', 'is', 'the', 'segment', 'leader', 'deliv', 'premium', 'interior', 'as', 'well', 'as', 'mani', 'first', 'in', 'segment', 'featur', 'not', 'yet', 'avail', 'in', 'it', 'rival', 'combin', 'with', 'the', 'effici', 'of', 'maruti\\u2019', 'engin', 'and', 'the', 'option', 'of', 'cng', 'the', 'baleno', 'is', 'a', 'veri', 'econom', 'car', 'to', 'own', 'compact', 'sedan', 'under', '10', 'lakh', 'honda', 'amazether', 'aren\\u2019t', 'mani', 'sedan', 'in', 'thi', 'price', 'segment', 'but', 'the', 'honda', 'amaz', 'stand', 'out', 'from', 'the', 'crowd', 'with', 'it', 'refin', 'engin', 'and', 'premium', 'interior', 'there', 'are', 'other', 'car', 'that', 'can', 'be', 'term', 'as', 'the', 'link', 'text', 'best', 'car', 'under', '10', 'lakh', 'url', 'http', 'www', 'spinni', 'com', 'blog', 'index', 'php', 'car', 'under', '10', 'lakh', 'utm', 'medium', 'quora', 'utm', 'sourc', 'car', 'under', '10', 'lakh', 'but', 'these', 'stand', 'out', 'in', 'particular', 'as', 'they', 'tick', 'a', 'lot', 'of', 'the', 'box', 'you', 'would', 'look', 'at', 'in', 'thi', 'price', 'segment']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 48,\n        \"min\": 11,\n        \"max\": 250,\n        \"num_unique_values\": 235,\n        \"samples\": [\n          146,\n          152,\n          136\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4020,\n        \"min\": 0,\n        \"max\": 410998,\n        \"num_unique_values\": 4663,\n        \"samples\": [\n          2753,\n          1970,\n          5570\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "\n",
        "# Load the cleaned dataset\n",
        "df = pd.read_csv('/content/tokenized_output.csv', on_bad_lines='skip')\n",
        "df1 = pd.read_csv('/content/test_data.csv', on_bad_lines='skip')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pS26-7Q2EOm7"
      },
      "outputs": [],
      "source": [
        "df['question'] = df['question'].fillna('')\n",
        "df['answer'] = df['answer'].fillna('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "axs9OAyJA_Dm"
      },
      "outputs": [],
      "source": [
        "\n",
        "logging.disable(logging.WARNING)\n",
        "warnings.filterwarnings(\"ignore\", message=\"Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some toke\")\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='transformers')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings)\n"
      ],
      "metadata": {
        "id": "BHLTYKFbThqv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup, AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(df['question'].tolist(), df['answer'].tolist(), truncation=True, padding=True)\n",
        "\n",
        "\n",
        "dataset = BERTDataset(train_encodings)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "# Training parameters\n",
        "epochs = 2\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "total_steps = len(dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    loop = tqdm(dataloader, leave=True)\n",
        "\n",
        "    for batch in loop:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        loss = outputs[0].mean()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        loop.set_description(f'Epoch {epoch}')\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "print('Training complete!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xuRIZodTDaM",
        "outputId": "270cf0b1-117f-4575-81a0-80776d718210"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 0: 100%|██████████| 1/1 [00:22<00:00, 22.13s/it, loss=0.23]\n",
            "Epoch 1: 100%|██████████| 1/1 [00:19<00:00, 19.48s/it, loss=-0.0381]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('/content/fine_tuned_bert_model')\n"
      ],
      "metadata": {
        "id": "wDRJ6ps-b62Z"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score\n",
        "!pip install nltk\n",
        "!pip install tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enlsNHntczuB",
        "outputId": "c979074b-e63b-4229-bfde-e95cfe2a95aa"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement datatests (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for datatests\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge_score import rouge_scorer\n",
        "from transformers import BertForQuestionAnswering, BertTokenizer, pipeline\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Load the fine-tuned model\n",
        "question_answering_model = BertForQuestionAnswering.from_pretrained('/content/fine_tuned_bert_model')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def predict_answer(question_answering_model, tokenizer, question, device=\"cuda\"):\n",
        "  \"\"\"\n",
        "  Generates an answer to a given question using a pre-trained question answering model\n",
        "\n",
        "  Args:\n",
        "      question_answering_model: The loaded question answering model.\n",
        "      tokenizer: The tokenizer used to preprocess text for the model.\n",
        "      question: The user-provided question.\n",
        "      device: The device to use for computation (\"cuda\" for GPU, \"cpu\" otherwise).\n",
        "\n",
        "  Returns:\n",
        "      The predicted answer string.\n",
        "  \"\"\"\n",
        "\n",
        "  inputs = tokenizer.encode_plus(question, return_tensors=\"pt\").to(device)\n",
        "  with torch.no_grad():\n",
        "    outputs = question_answering_model(**inputs)\n",
        "    answer_start = torch.argmax(outputs.start_logits)\n",
        "    answer_end = torch.argmax(outputs.end_logits) + 1\n",
        "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))\n",
        "  return answer\n",
        "\n",
        "test = pd.read_csv('/content/test_data.csv')\n",
        "\n",
        "def evaluate_predictions(ground_truth_answers, generated_answers):\n",
        "  \"\"\"\n",
        "  Computes various evaluation metrics for a set of predicted answers\n",
        "\n",
        "  Args:\n",
        "      ground_truth_answers: A list of reference answer strings.\n",
        "      generated_answers: A list of predicted answer strings.\n",
        "\n",
        "  Returns:\n",
        "      A tuple containing average BLEU, ROUGE-L, and F1 scores.\n",
        "  \"\"\"\n",
        "\n",
        "  bleu_scores = []\n",
        "  rouge_l_scores = []\n",
        "  f1_scores = []\n",
        "\n",
        "  rouge = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
        "\n",
        "  for ref, pred in zip(ground_truth_answers, generated_answers):\n",
        "    # BLEU score\n",
        "    bleu_score = sentence_bleu([ref.split()], pred.split())\n",
        "    bleu_scores.append(bleu_score)\n",
        "\n",
        "    # ROUGE-L score\n",
        "    rouge_l_score = rouge.score(ref, pred)[\"rougeL\"].fmeasure\n",
        "    rouge_l_scores.append(rouge_l_score)\n",
        "\n",
        "    # F1-score\n",
        "    ref_tokens = set(ref.split())\n",
        "    pred_tokens = set(pred.split())\n",
        "    common_tokens = ref_tokens.intersection(pred_tokens)\n",
        "\n",
        "    if len(common_tokens) == 0:\n",
        "      f1 = 0.0\n",
        "    else:\n",
        "      precision = len(common_tokens) / len(pred_tokens)\n",
        "      recall = len(common_tokens) / len(ref_tokens)\n",
        "      f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "  avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
        "  avg_rouge_l = sum(rouge_l_scores) / len(rouge_l_scores)\n",
        "  avg_f1 = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "  return avg_bleu, avg_rouge_l, avg_f1\n",
        "\n",
        "# Example usage\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "question_answering_model.to(device)\n",
        "\n",
        "# Assuming 'test' is a DataFrame with 'question' and 'answer' columns\n",
        "questions = test.question\n",
        "ground_truth_answers = test.answer\n",
        "\n",
        "predicted_answers = [predict_answer(question_answering_model, tokenizer, q, device) for q in questions]\n",
        "\n",
        "avg_bleu, avg_rouge_l, avg_f1 = evaluate_predictions(ground_truth_answers, predicted_answers)\n",
        "\n",
        "print(f\"Average BLEU Score: {avg_bleu}\")\n",
        "print(f\"Average ROUGE-L Score: {avg_rouge_l}\")\n",
        "print(f\"Average F1 Score: {avg_f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zod6YdV7cEfE",
        "outputId": "3e59071d-77b5-4659-b8fa-8b48c46e78c4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEU Score: 8.506863021393776e-05\n",
            "Average ROUGE-L Score: 0.010821782976539216\n",
            "Average F1 Score: 0.010937068334262954\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNYm+IOO8mSTI+vQBu1zdtu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}